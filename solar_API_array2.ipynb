{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NREL Solar Resource Data - lat/long file import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This program uses the Solar Resource Data API provided by NREL and returns various solar power related parameters for a given latitude and longitude.  The goal of the program is to take in a file of lat and long values and iterate through, pulling the values of interest and then writing them to a new file in a format usable for creation of maps and analytical purposes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **DATA RETURNED**  \n",
    "Average Direct Normal Irradiance - measured surface perpendicular to direct solar rays (avg_dni)  \n",
    "Average Global Horizontal Irradiance - measured surface horizontal to the ground (avg_ghi)  \n",
    "Average Tilt at Latitude (avg_lat_tilt)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **INFORMATION & RESEARCH**\n",
    "https://developer.nrel.gov/docs/solar/solar-resource-v1/   \n",
    "https://en.wikipedia.org/wiki/Solar_irradiance  \n",
    "https://www.3tier.com/en/support/solar-online-tools/what-global-horizontal-irradiance-solar-prospecting/  \n",
    "https://www.pveducation.org/pvcdrom/properties-of-sunlight/measurement-of-solar-radiation   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import requests, json, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review list of lat longs to use for reading into API\n",
    "with open('location_values_sample.csv', newline='') as csvfile:\n",
    "    loc_reader = csv.reader(csvfile)\n",
    "    for loc in loc_reader:\n",
    "        print(loc, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring lat / long csv into a dataframe\n",
    "file_name = 'location_values_sample.csv'\n",
    "df = pd.read_csv(file_name) \n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE REQUESTS AND SAVE TO A FILE FOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name for saving all results\n",
    "all_filename = input(\"filename for all data including .csv: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name for saving yearly results\n",
    "yearly_filename = input(\"filename for yearly data including .csv: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through csv and query using lat / long to get average monthly DNI and save to a csv\n",
    "\n",
    "try:\n",
    "    # create URL using values in database\n",
    "    lat_count = 0\n",
    "    long_count = 0\n",
    "    while lat_count < len(df):\n",
    "        lat = df.at[lat_count,'lat']\n",
    "        long = df.at[long_count,'long']\n",
    "        API_ENDPOINT = 'https://developer.nrel.gov/api/solar/solar_resource/v1.json?api_key=aO3yoslbHz6Pg9vrVdVGjA47Jrv1TnjOfOhDJj0L&lat=%s&lon=%s' % (lat,long)\n",
    "        full_url = API_ENDPOINT\n",
    "        print()\n",
    "        print('URL: ', full_url)    \n",
    "\n",
    "        # send out the request for information\n",
    "        response = requests.get(full_url)\n",
    "        # check its status to see if all is well\n",
    "        print('Made request, response status: ', response.status_code)\n",
    "        # determine if results were returned or another error code\n",
    "        if response.status_code == 200:\n",
    "            # 200 is all good\n",
    "            results = json.loads(response.text)\n",
    "        elif response.status_code == 429:\n",
    "            # 429 is request limit reached\n",
    "            raise Exception \n",
    "        else: \n",
    "            # other exception noted on NREL is 422 for invalid parameter\n",
    "            print()\n",
    "            print(\"One of your parameters is not valid.\")\n",
    "\n",
    "        # append all to a file\n",
    "        with open(all_filename, 'a', newline=\"\") as file_name:\n",
    "            write_file = csv.writer(file_name, lineterminator=\"\\r\")\n",
    "            for k, v in results['inputs'].items():\n",
    "                write_file.writerow([k, v])\n",
    "            for key, value in results['outputs'].items():\n",
    "                write_file.writerow([key, value])\n",
    "\n",
    "        # append to the yearly file\n",
    "        with open(yearly_filename, 'a') as print_file:\n",
    "            print_file.write(str(lat) + \"\\n\")\n",
    "            print_file.write(str(long) + \"\\n\")\n",
    "            print_file.write(str(results['outputs']['avg_dni']['annual'])) # result needs to be a string, not integer\n",
    "            print_file.write(\"\\n\")\n",
    "\n",
    "        # add 1 to lat / long counters to move to next values for next iteration\n",
    "        lat_count = lat_count + 1\n",
    "        long_count = long_count + 1\n",
    "    else:\n",
    "        print()\n",
    "        print(\"You've reached the end of the file.\")\n",
    "\n",
    "except Exception:\n",
    "    print()\n",
    "    # print exception if the hourly request limit imposed by NREL is reached\n",
    "    print(\"You've reached your hourly limit of 1000 requests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORMAT YEARLY VALUES AND SAVE TO A FILE FORMATTED FOR GIS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the request results to a dataframe\n",
    "result_file = yearly_filename\n",
    "result_df = pd.read_csv(result_file, header=None) \n",
    "result_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange values in file to better format and add header info\n",
    "df_new = (pd.DataFrame(result_df.values.reshape(-1, 3), \n",
    "                    columns=['lat','long','avg_yrly_dni']))\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge original dataframe with city and state with resultant, reformatted dataframe\n",
    "df_all = pd.merge(df, df_new, on=['lat','long'], how='left')\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to a new csv\n",
    "final_file = input(\"name of reformatted request result file, include .csv: \")\n",
    "df_all.to_csv(final_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
